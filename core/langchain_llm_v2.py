"""
LangChain LCEL ê¸°ë°˜ LLM í´ë¼ì´ì–¸íŠ¸ (ì‹œí€¸ì…œ ì²´ì¸ ë²„ì „)
"""
import os
from typing import Optional, Dict, Any, List
import json
from dotenv import load_dotenv

load_dotenv()
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnablePassthrough
import yaml


class LangChainLLM:
    """LangChain LCEL ê¸°ë°˜ LLM í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, config_path: str = "config.yaml"):
        # config.yaml ë¡œë“œ
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # OpenAI API í‚¤ ì„¤ì •
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # LangChain ChatOpenAI ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=500,
            api_key=api_key
        )

        # JSON íŒŒì„œ
        self.json_parser = JsonOutputParser()

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ì¬ì‚¬ìš© ê°€ëŠ¥)
        self.intent_prompt_template = self._create_intent_prompt_template()
        self.response_prompt_template = self._create_response_prompt_template()
        self.chat_prompt_template = self._create_chat_prompt_template()

        # ì‹œí€¸ì…œ ì²´ì¸ êµ¬ì„± (LCEL)
        self.intent_chain = self.intent_prompt_template | self.llm | self.json_parser

    def _create_intent_prompt_template(self) -> ChatPromptTemplate:
        """ì˜ë„ íŒŒì‹±ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        system_template = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ê±´ê°•/í• ì¼ ê´€ë¦¬ ë´‡ì˜ íŒŒì„œì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ì˜ë„(intent):
- sleep: ìˆ˜ë©´ (ì‹œê°„ ê³„ì‚° í•„ìš”ì‹œ ìë™ ê³„ì‚°)
- workout: ìš´ë™
- protein: ë‹¨ë°±ì§ˆ ì„­ì·¨
- weight: ì²´ì¤‘
- task_add: í• ì¼ ì¶”ê°€
- task_complete: í• ì¼ ì™„ë£Œ
- study: ê³µë¶€/í•™ìŠµ (ì‹œê°„ ê¸°ë¡)
- learning_log: í•™ìŠµ ê¸°ë¡ (ìƒˆë¡œìš´ ì§€ì‹/ìŠ¤í‚¬ ìŠµë“)
- summary: ìš”ì•½
- progress: ì§„í–‰ë„
- chat: ì¼ë°˜ ëŒ€í™”

ë³µí•© ëª…ë ¹ì¸ ê²½ìš° JSON ë°°ì—´ë¡œ, ë‹¨ì¼ ëª…ë ¹ì€ JSON ê°ì²´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "ìƒˆë²½3ì‹œë¶€í„° 12ì‹œê¹Œì§€ ì¤ì–´" â†’ {{"intent": "sleep", "entities": {{"sleep_hours": 9}}, "confidence": 0.95}}
- "ì–´ì œ 7ì‹œê°„ ìê³  30ë¶„ ìš´ë™í–ˆì–´" â†’ [
    {{"intent": "sleep", "entities": {{"sleep_hours": 7, "date": "ì–´ì œ"}}, "confidence": 0.95}},
    {{"intent": "workout", "entities": {{"workout_minutes": 30, "date": "ì–´ì œ"}}, "confidence": 0.95}}
  ]
- "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcpì— ëŒ€í•´ ì•Œê²Œëì–´" â†’ {{"intent": "learning_log", "entities": {{"title": "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcp", "content": "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcpì— ëŒ€í•´ í•™ìŠµí•¨"}}, "confidence": 0.95}}
- "ë‚´ì¼ ì¼ë³¸ì—¬í–‰ê°ˆë•Œ ì§ ì±™ê²¨ì•¼í•´" â†’ {{"intent": "task_add", "entities": {{"task_title": "ì§ ì±™ê¸°ê¸°", "due": "ë‚´ì¼"}}, "confidence": 0.95}}

ë³µì¡í•œ ìˆ˜ë©´ íŒ¨í„´ë„ ê³„ì‚°í•´ì£¼ì„¸ìš”:
- "11ì‹œì— ì¤ë‹¤ê°€ 3ì‹œì— ì¼ì–´ë‚˜ì„œ ë‹¤ì‹œ 8ì‹œì— ì¤ë‹¤ê°€ 14ì‹œì— ì¼ì–´ë‚¬ì–´" â†’ ì´ 10ì‹œê°„ ìˆ˜ë©´

í•™ìŠµ ê¸°ë¡ (learning_log)ì€ 'ì•Œê²Œëì–´', 'ë°°ì› ì–´', 'ê¹¨ë‹¬ì•˜ì–´', 'ê¸°ì–µí•´ë‘¬' ë“±ì˜ í‘œí˜„ì´ ìˆì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

**ì¤‘ìš”: entities í‚¤ ì´ë¦„ ê·œì¹™**
- task_add: "task_title" (í• ì¼ ì œëª©)
- task_complete: "task_id" (í• ì¼ ID)
- sleep: "sleep_hours" (ìˆ˜ë©´ ì‹œê°„)
- workout: "workout_minutes" (ìš´ë™ ì‹œê°„, ë¶„ ë‹¨ìœ„)
- protein: "protein_grams" (ë‹¨ë°±ì§ˆ, ê·¸ë¨)
- weight: "weight_kg" (ì²´ì¤‘, kg)
- study: "study_hours" ë˜ëŠ” "study_minutes" (ê³µë¶€ ì‹œê°„)
- learning_log: "title" (í•™ìŠµ ë‚´ìš© ì œëª©), "content" (ìƒì„¸ ë‚´ìš©)

ë°˜ë“œì‹œ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
ì˜¬ë°”ë¥¸ í˜•ì‹:
{{"intent": "sleep", "entities": {{}}, "confidence": 0.95}}
ë˜ëŠ”
[{{"intent": "sleep", ...}}, {{"intent": "workout", ...}}]"""

        human_template = """ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ì´ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
ë³µí•© ëª…ë ¹ì´ë©´ ë°°ì—´, ë‹¨ì¼ ëª…ë ¹ì´ë©´ ê°ì²´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""

        return ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])

    def _create_response_prompt_template(self) -> ChatPromptTemplate:
        """ì‘ë‹µ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        system_template = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í—¬ìŠ¤ì¼€ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê±´ê°• ë°ì´í„°ë¥¼ ê¸°ë¡í•˜ê³  ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ë©°, ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤.
í†¤: {tone}"""

        human_template = """ì‚¬ìš©ì: "{user_input}"

ì²˜ë¦¬ ê²°ê³¼: {context}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” ì‘ë‹µì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        return ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])

    def _create_chat_prompt_template(self) -> ChatPromptTemplate:
        """ì¼ë°˜ ëŒ€í™”ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        system_template = """ë‹¹ì‹ ì€ Horcrux, ì¹œê·¼í•œ ê±´ê°•/í• ì¼ ê´€ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©°, ê±´ê°• ê´€ë¦¬ë¥¼ ê²©ë ¤í•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤."""

        human_template = "{user_input}"

        return ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template(human_template)
        ])

    def parse_intent(
        self,
        user_input: str,
        context: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì…ë ¥ íŒŒì‹± (ì‹œí€¸ì…œ ì²´ì¸ ì‚¬ìš©)

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (í˜„ì¬ ë¯¸ì‚¬ìš©)

        Returns:
            íŒŒì‹± ê²°ê³¼ (ë‹¨ì¼ ë˜ëŠ” ë³µí•©)
        """
        try:
            # ì‹œí€¸ì…œ ì²´ì¸ ì‹¤í–‰: Prompt â†’ LLM â†’ JsonParser
            parsed = self.intent_chain.invoke({"user_input": user_input})

            # ë°°ì—´ì¸ ê²½ìš° (ë³µí•© ëª…ë ¹)
            if isinstance(parsed, list):
                for item in parsed:
                    item["success"] = True
                    item["parser"] = "langchain_lcel"

                return {
                    "success": True,
                    "multiple": True,
                    "intents": parsed,
                    "parser": "langchain_lcel"
                }

            # ê°ì²´ì¸ ê²½ìš° (ë‹¨ì¼ ëª…ë ¹)
            else:
                parsed["success"] = True
                parsed["parser"] = "langchain_lcel"
                return parsed

        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬
            return {
                "success": True,
                "intent": "chat",
                "entities": {"message": user_input},
                "confidence": 0.8,
                "parser": "langchain_lcel"
            }

        except Exception as e:
            print(f"LangChain ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "intent": "unknown",
                "entities": {},
                "confidence": 0.0,
                "error": str(e)
            }

    def generate_response(
        self,
        user_input: str,
        context: str = "",
        tone: str = "friendly"
    ) -> str:
        """
        ëŒ€í™”í˜• ì‘ë‹µ ìƒì„± (ì‹œí€¸ì…œ ì²´ì¸ ì‚¬ìš©)

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            context: ì²˜ë¦¬ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸
            tone: ì‘ë‹µ í†¤

        Returns:
            ëŒ€í™”í˜• ì‘ë‹µ
        """
        try:
            # ì‹œí€¸ì…œ ì²´ì¸ ì‹¤í–‰
            response_chain = self.response_prompt_template | self.llm
            response = response_chain.invoke({
                "user_input": user_input,
                "context": context,
                "tone": tone
            })
            return response.content.strip()

        except Exception as e:
            print(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return context  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜

    def chat(
        self,
        user_input: str,
        chat_history: List[Dict[str, str]] = None
    ) -> str:
        """
        ì¼ë°˜ ëŒ€í™” (ì±—ë´‡ ëª¨ë“œ)

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            chat_history: ëŒ€í™” ì´ë ¥ (í–¥í›„ êµ¬í˜„)

        Returns:
            AI ì‘ë‹µ
        """
        try:
            # ì‹œí€¸ì…œ ì²´ì¸ ì‹¤í–‰
            chat_chain = self.chat_prompt_template | self.llm
            response = chat_chain.invoke({"user_input": user_input})
            return response.content.strip()

        except Exception as e:
            print(f"ëŒ€í™” ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìˆì—ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜…"


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    llm = LangChainLLM()

    # í…ŒìŠ¤íŠ¸
    test_cases = [
        "7ì‹œê°„ ì¤ì–´",
        "ì–´ì œ 8ì‹œê°„ ìê³  30ë¶„ ìš´ë™í–ˆì–´",
        "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcpì— ëŒ€í•´ ì•Œê²Œëì–´",
    ]

    for test in test_cases:
        print(f"\nì…ë ¥: {test}")
        result = llm.parse_intent(test)
        print(f"íŒŒì‹± ê²°ê³¼: {result}")
