"""
LangChain ê¸°ë°˜ LLM í´ë¼ì´ì–¸íŠ¸
"""
import os
from typing import Optional, Dict, Any, List
import json
from dotenv import load_dotenv

# .env íŒŒì¼ ìë™ ë¡œë“œ
load_dotenv()
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
import yaml


class LangChainLLM:
    """LangChain ê¸°ë°˜ LLM í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, config_path: str = "config.yaml"):
        # config.yaml ë¡œë“œ
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        llm_config = config.get("llm", {})

        # OpenAI API í‚¤ ì„¤ì •
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # LangChain ChatOpenAI ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸
            temperature=0.7,
            max_tokens=500,
            api_key=api_key
        )

        # JSON íŒŒì„œ
        self.json_parser = JsonOutputParser()

    def parse_intent(
        self,
        user_input: str,
        context: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì…ë ¥ íŒŒì‹± (ëŒ€í™”í˜• ì…ë ¥ ë¶„ì„)

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸

        Returns:
            íŒŒì‹± ê²°ê³¼ (ë‹¨ì¼ ë˜ëŠ” ë³µí•©)
        """
        system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ê±´ê°•/í• ì¼ ê´€ë¦¬ ë´‡ì˜ íŒŒì„œì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ì˜ë„(intent):
- sleep: ìˆ˜ë©´ (ì‹œê°„ ê³„ì‚° í•„ìš”ì‹œ ìë™ ê³„ì‚°)
- workout: ìš´ë™
- protein: ë‹¨ë°±ì§ˆ ì„­ì·¨
- weight: ì²´ì¤‘
- task_add: í• ì¼ ì¶”ê°€
- task_complete: í• ì¼ ì™„ë£Œ
- study: ê³µë¶€/í•™ìŠµ (ì‹œê°„ ê¸°ë¡)
- learning_log: í•™ìŠµ ê¸°ë¡ (ìƒˆë¡œìš´ ì§€ì‹/ìŠ¤í‚¬ ìŠµë“)
- summary: ìš”ì•½
- progress: ì§„í–‰ë„
- chat: ì¼ë°˜ ëŒ€í™”

ë³µí•© ëª…ë ¹ì¸ ê²½ìš° JSON ë°°ì—´ë¡œ, ë‹¨ì¼ ëª…ë ¹ì€ JSON ê°ì²´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "ìƒˆë²½3ì‹œë¶€í„° 12ì‹œê¹Œì§€ ì¤ì–´" â†’ {{"intent": "sleep", "entities": {{"sleep_hours": 9}}, "confidence": 0.95}}
- "ì–´ì œ 7ì‹œê°„ ìê³  30ë¶„ ìš´ë™í–ˆì–´" â†’ [
    {{"intent": "sleep", "entities": {{"sleep_hours": 7, "date": "ì–´ì œ"}}, "confidence": 0.95}},
    {{"intent": "workout", "entities": {{"workout_minutes": 30, "date": "ì–´ì œ"}}, "confidence": 0.95}}
  ]
- "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcpì— ëŒ€í•´ ì•Œê²Œëì–´" â†’ {{"intent": "learning_log", "entities": {{"title": "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcp", "content": "í”„ë¡¬í¬íŠ¸ í…œí”Œë¦¿ê³¼ chrome mcpì— ëŒ€í•´ í•™ìŠµí•¨"}}, "confidence": 0.95}}
- "ë‚´ì¼ ì¼ë³¸ì—¬í–‰ê°ˆë•Œ ì§ ì±™ê²¨ì•¼í•´" â†’ {{"intent": "task_add", "entities": {{"task_title": "ì§ ì±™ê¸°ê¸°", "due": "ë‚´ì¼"}}, "confidence": 0.95}}

ë³µì¡í•œ ìˆ˜ë©´ íŒ¨í„´ë„ ê³„ì‚°í•´ì£¼ì„¸ìš”:
- "11ì‹œì— ì¤ë‹¤ê°€ 3ì‹œì— ì¼ì–´ë‚˜ì„œ ë‹¤ì‹œ 8ì‹œì— ì¤ë‹¤ê°€ 14ì‹œì— ì¼ì–´ë‚¬ì–´" â†’ ì´ 10ì‹œê°„ ìˆ˜ë©´

í•™ìŠµ ê¸°ë¡ (learning_log)ì€ 'ì•Œê²Œëì–´', 'ë°°ì› ì–´', 'ê¹¨ë‹¬ì•˜ì–´', 'ê¸°ì–µí•´ë‘¬' ë“±ì˜ í‘œí˜„ì´ ìˆì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

**ì¤‘ìš”: entities í‚¤ ì´ë¦„ ê·œì¹™**
- task_add: "task_title" (í• ì¼ ì œëª©)
- task_complete: "task_id" (í• ì¼ ID)
- sleep: "sleep_hours" (ìˆ˜ë©´ ì‹œê°„)
- workout: "workout_minutes" (ìš´ë™ ì‹œê°„, ë¶„ ë‹¨ìœ„)
- protein: "protein_grams" (ë‹¨ë°±ì§ˆ, ê·¸ë¨)
- weight: "weight_kg" (ì²´ì¤‘, kg)
- study: "study_hours" ë˜ëŠ” "study_minutes" (ê³µë¶€ ì‹œê°„)
- learning_log: "title" (í•™ìŠµ ë‚´ìš© ì œëª©), "content" (ìƒì„¸ ë‚´ìš©)"""

        user_prompt = f"""ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ì´ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
ë³µí•© ëª…ë ¹ì´ë©´ ë°°ì—´, ë‹¨ì¼ ëª…ë ¹ì´ë©´ ê°ì²´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""

        try:
            # JsonOutputParser ì„¤ì •
            parser = JsonOutputParser()

            # í”„ë¡¬í”„íŠ¸ì— í¬ë§· ì§€ì‹œ ì¶”ê°€
            format_instructions = """
ë°˜ë“œì‹œ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
ì˜¬ë°”ë¥¸ í˜•ì‹:
{"intent": "sleep", "entities": {...}, "confidence": 0.95}
ë˜ëŠ”
[{"intent": "sleep", ...}, {"intent": "workout", ...}]
"""

            # LangChain ë©”ì‹œì§€ ìƒì„±
            messages = [
                SystemMessage(content=system_prompt + "\n" + format_instructions),
                HumanMessage(content=user_prompt)
            ]

            # LLM í˜¸ì¶œ
            response = self.llm.invoke(messages)

            # JsonOutputParserë¡œ ìë™ íŒŒì‹±
            try:
                parsed = parser.parse(response.content)

                # ë°°ì—´ì¸ ê²½ìš° (ë³µí•© ëª…ë ¹)
                if isinstance(parsed, list):
                    for item in parsed:
                        item["success"] = True
                        item["parser"] = "langchain"

                    return {
                        "success": True,
                        "multiple": True,
                        "intents": parsed,
                        "parser": "langchain"
                    }

                # ê°ì²´ì¸ ê²½ìš° (ë‹¨ì¼ ëª…ë ¹)
                else:
                    parsed["success"] = True
                    parsed["parser"] = "langchain"
                    return parsed

            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬
                return {
                    "success": True,
                    "intent": "chat",
                    "entities": {"message": user_input},
                    "confidence": 0.8,
                    "parser": "langchain",
                    "response": response.content  # AI ì‘ë‹µ ê·¸ëŒ€ë¡œ ì „ë‹¬
                }

        except Exception as e:
            print(f"LangChain ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "intent": "unknown",
                "entities": {},
                "confidence": 0.0,
                "error": str(e)
            }

    def generate_response(
        self,
        user_input: str,
        context: str = "",
        tone: str = "friendly"
    ) -> str:
        """
        ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            context: ì²˜ë¦¬ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸
            tone: ì‘ë‹µ í†¤ (friendly, professional, casual)

        Returns:
            ëŒ€í™”í˜• ì‘ë‹µ
        """
        system_prompt = f"""ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í—¬ìŠ¤ì¼€ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê±´ê°• ë°ì´í„°ë¥¼ ê¸°ë¡í•˜ê³  ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ë©°, ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤.
í†¤: {tone}"""

        user_prompt = f"""ì‚¬ìš©ì: "{user_input}"

ì²˜ë¦¬ ê²°ê³¼: {context}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” ì‘ë‹µì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]

            response = self.llm.invoke(messages)
            return response.content.strip()

        except Exception as e:
            print(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return context  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜

    def chat(
        self,
        user_input: str,
        chat_history: List[Dict[str, str]] = None
    ) -> str:
        """
        ì¼ë°˜ ëŒ€í™” (ì±—ë´‡ ëª¨ë“œ)

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            chat_history: ëŒ€í™” ì´ë ¥

        Returns:
            AI ì‘ë‹µ
        """
        system_prompt = """ë‹¹ì‹ ì€ LifeBot, ì¹œê·¼í•œ ê±´ê°•/í• ì¼ ê´€ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©°, ê±´ê°• ê´€ë¦¬ë¥¼ ê²©ë ¤í•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤."""

        messages = [SystemMessage(content=system_prompt)]

        # ëŒ€í™” ì´ë ¥ ì¶”ê°€
        if chat_history:
            for msg in chat_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                else:
                    messages.append(SystemMessage(content=msg["content"]))

        messages.append(HumanMessage(content=user_input))

        try:
            response = self.llm.invoke(messages)
            return response.content.strip()

        except Exception as e:
            print(f"ëŒ€í™” ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìˆì—ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜…"


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # API í‚¤ ì„¤ì • í•„ìš”
    os.environ["OPENAI_API_KEY"] = "your-api-key-here"

    llm = LangChainLLM()

    # í…ŒìŠ¤íŠ¸
    test_cases = [
        "ì–´ì œ 11ì‹œì— ì¤ë‹¤ê°€ ìƒˆë²½ 3ì‹œì— ì¼ì–´ë‚˜ì„œ ë°¥ë¨¹ê³  ë‹¤ì‹œ ì˜¤ì „ 8ì‹œì¯¤ ì¤ë‹¤ê°€ 2ì‹œì— ì¼ì–´ë‚¬ì–´ ã…‹ã…‹",
        "ì˜¤ëŠ˜ ì•½ì†ì€ ì €ë… 8ì‹œë°˜ì— ì˜í™”ë³´ëŠ”ê±° ìˆê³ , ì ì€ ì–´ì œ ìƒˆë²½3ì‹œë¶€í„° 12ì‹œê¹Œì§€ ì¤ì–´",
        "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ ì¢‹ë„¤ìš”",
    ]

    for test in test_cases:
        print(f"\nì…ë ¥: {test}")
        result = llm.parse_intent(test)
        print(f"íŒŒì‹± ê²°ê³¼: {result}")

        if result.get("intent") == "chat":
            chat_response = llm.chat(test)
            print(f"ëŒ€í™” ì‘ë‹µ: {chat_response}")